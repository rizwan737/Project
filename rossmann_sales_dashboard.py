# -*- coding: utf-8 -*-
"""Rossmann Sales Dashboard

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10O-7jomIRRBpDe1dYVqhimsM6xVcJRBf
"""

import streamlit as st
import pandas as pd
import numpy as np
import pickle
import os
import matplotlib.pyplot as plt
import lightgbm as lgb
from PIL import Image

# --- Configuration and Helpers ---
MODEL_FILE = 'lgbm_model.pkl'
FEATURE_FILE = 'features.pkl'
st.set_page_config(layout="wide", page_title="Rossmann Sales Predictor", initial_sidebar_state="expanded")

# --- Custom Styling for Professional Look ---
def set_custom_styles():
    """Injects custom CSS for a cleaner, modern look."""
    st.markdown("""
        <style>
        .css-1d391kg {padding-top: 35px;} /* Adjust padding for main content */
        .css-1y4c50r {padding: 1.5rem 1rem;} /* Adjust padding for widget containers */

        /* Custom Header Styling */
        h1 {
            color: #004d99; /* Deep blue color */
            font-size: 2.5em;
            border-bottom: 2px solid #e0e0e0;
            padding-bottom: 10px;
        }

        /* Metric Styling */
        div[data-testid="stMetric"] {
            background-color: #f0f8ff; /* Light, subtle background */
            border-radius: 10px;
            padding: 15px;
            box-shadow: 2px 2px 5px rgba(0,0,0,0.1);
        }

        /* Sidebar Styling */
        [data-testid="stSidebar"] {
            background-color: #f7f7f7;
            padding: 20px;
        }

        /* Button Styling */
        .stButton>button {
            border-radius: 8px;
            font-weight: bold;
            transition: all 0.2s;
        }
        .stButton>button:hover {
            opacity: 0.9;
        }

        /* Chart Caption Style */
        .stPlotlyChart {
            border: 1px solid #e0e0e0;
            border-radius: 8px;
            padding: 10px;
            margin-top: 15px;
        }
        </style>
    """, unsafe_allow_html=True)


def load_resources():
    """Load the trained model, feature list, and dummy data for the app."""
    try:
        # Load Model
        with open(MODEL_FILE, 'rb') as f:
            model = pickle.load(f)

        # Load Features
        with open(FEATURE_FILE, 'rb') as f:
            features = pickle.load(f)

        return model, features
    except FileNotFoundError:
        st.error(f"Required files ({MODEL_FILE} or {FEATURE_FILE}) not found. Please run `model_trainer.py` first.")
        return None, None

def feature_engineer_single(df):
    """
    Applies the same feature engineering steps as the training script
    to a single DataFrame (for uploaded data).
    """
    # Defensive copy of the DataFrame
    df = df.copy()

    if 'Date' in df.columns:
        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
        # Drop rows where Date conversion failed
        df = df.dropna(subset=['Date'])

        df['Year'] = df['Date'].dt.year
        df['Month'] = df['Date'].dt.month
        df['Day'] = df['Date'].dt.day
        # Use simple week number if isocalendar fails or is slow
        try:
             df['WeekOfYear'] = df['Date'].dt.isocalendar().week.astype(int)
        except AttributeError:
             df['WeekOfYear'] = df['Date'].dt.isocalendar().week.astype(int)

        df['DayOfYear'] = df['Date'].dt.dayofyear
        df['DayOfWeek'] = df['Date'].dt.dayofweek

    # Imputation and Feature Creation (must match model_trainer.py)
    if 'CompetitionDistance' in df.columns:
        # Using a large placeholder based on training script logic
        df['CompetitionDistance'] = df['CompetitionDistance'].fillna(100000.0)

    for col in ['CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2SinceWeek', 'Promo2SinceYear']:
        if col in df.columns:
            df[col] = df[col].fillna(0).astype(int)

    if 'PromoInterval' in df.columns:
        df['PromoInterval'] = df['PromoInterval'].fillna('None')

    if all(col in df.columns for col in ['CompetitionOpenSinceYear', 'CompetitionOpenSinceMonth', 'Date']):
        # Competition Open Time (in months)
        df['CompetitionOpen'] = 12 * (df['Year'] - df['CompetitionOpenSinceYear']) + \
                                (df['Month'] - df['CompetitionOpenSinceMonth'])
        df['CompetitionOpen'] = df['CompetitionOpen'].apply(lambda x: x if x > 0 else 0)

    if 'PromoInterval' in df.columns:
        month_to_str = {1: 'Jan', 2: 'Feb', 3: 'Mar', 4: 'Apr', 5: 'May', 6: 'Jun',
                        7: 'Jul', 8: 'Aug', 9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dec'}
        df['MonthStr'] = df['Month'].map(month_to_str)

        # Check if the current month is one of the months listed in PromoInterval
        df['IsPromo2Month'] = df.apply(lambda row:
                                       row['MonthStr'] in row['PromoInterval'] if row['Promo2'] == 1 else 0,
                                       axis=1).astype(int)
        df = df.drop(columns=['MonthStr'])

    return df

def preprocess_for_prediction(data_df, features):
    """Applies Label Encoding and column alignment for prediction."""
    processed_df = data_df.copy()

    # 1. Feature Engineering
    processed_df = feature_engineer_single(processed_df)

    # 2. Encoding
    categorical_cols = ['StoreType', 'Assortment', 'StateHoliday', 'PromoInterval']

    for col in categorical_cols:
        if col in processed_df.columns:
            # Re-map categories to integers for prediction consistency
            processed_df[col] = processed_df[col].astype('category').cat.codes
            processed_df[col] = processed_df[col].astype('category')

    # 3. Column Alignment
    # Filter to only keep the features the model was trained on
    X_pred = processed_df.reindex(columns=features, fill_value=0)

    # Handle missing 'Open' in the test/uploaded data
    if 'Open' in X_pred.columns:
        X_pred['Open'] = X_pred['Open'].fillna(1).astype(int)

    # 4. Final Data Types Check (important for LightGBM)
    for col in X_pred.columns:
        if col in categorical_cols:
            X_pred[col] = X_pred[col].astype('category')
        # Ensure no accidental object/string columns remain
        elif X_pred[col].dtype == object:
            X_pred[col] = pd.to_numeric(X_pred[col], errors='coerce').fillna(0) # Convert remaining objects to numeric

    return X_pred

def predict_sales(model, X_data):
    """Generates sales predictions."""
    predictions_log = model.predict(X_data, num_iteration=model.best_iteration)
    predictions = np.expm1(predictions_log)

    # Post-processing: ensure no negative sales
    predictions[predictions < 0] = 0

    # Handle closed stores: check if 'Open' column exists and is 0
    # Note: X_data is the *processed* DataFrame
    if 'Open' in X_data.columns:
        predictions[X_data['Open'] == 0] = 0

    return predictions

# --- Chart Generation Functions ---

def plot_sales_over_time(df):
    """Generates a line chart of sales aggregated by date."""
    # FIX: Ensure the 'Date' column is explicitly converted to datetime type
    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')

    # Drop any rows where Date conversion failed, just to be safe
    df = df.dropna(subset=['Date'])

    # Now set the index and resample
    df_agg = df.set_index('Date')['Predicted Sales (EUR)'].resample('D').sum().reset_index()
    df_agg = df_agg.rename(columns={'Predicted Sales (EUR)': 'Total Predicted Sales'})

    st.line_chart(df_agg.set_index('Date'))
    st.caption("Daily total predicted sales across all stores in the uploaded dataset.")

def plot_sales_distribution(df):
    """Generates a histogram/distribution chart of predicted sales."""

    fig, ax = plt.subplots(figsize=(8, 4))

    # Filter out 0 sales for clearer distribution of active sales
    active_sales = df[df['Predicted Sales (EUR)'] > 0]['Predicted Sales (EUR)']

    ax.hist(active_sales, bins=30, edgecolor='black', color='#00a6ff', alpha=0.7)
    ax.set_title('Distribution of Active Predicted Daily Sales')
    ax.set_xlabel('Predicted Sales (EUR)')
    ax.set_ylabel('Frequency')
    ax.grid(axis='y', linestyle='--', alpha=0.6)

    st.pyplot(fig)
    st.caption("Frequency distribution helps identify the most common sales volume ranges.")

# --- Main Application ---
def main():
    set_custom_styles()

    # --- Header and Branding ---
    st.title("üõçÔ∏è Rossmann Store Sales Predictor")
    st.markdown("A Machine Learning dashboard powered by **LightGBM** to forecast daily sales based on historical trends, promotions, and store characteristics. ")
    st.markdown("---")

    model, features = load_resources()

    if model is None or features is None:
        # If files are missing, load_resources() has already displayed an error.
        # We stop execution here to prevent further errors like the one reported.
        st.stop()

    # --- Sidebar for Upload and Configuration ---
    with st.sidebar:
        st.header("1. Data Input")
        uploaded_file = st.file_uploader("Upload your test data (e.g., `test.csv`)", type=['csv'])
        st.markdown("---")

        st.header("2. Model Overview")
        st.metric("Model Algorithm", "LightGBM")

        # --- FIX APPLIED HERE ---
        # Only display the feature count if 'features' successfully loaded (is not None)
        if features is not None:
            st.metric("Total Features Used", len(features))
        # ------------------------

        st.info("The model relies on time, store type, promotions, and competition data.")

    # --- Main Content Tabs ---
    tab1, tab2 = st.tabs(["üöÄ Sales Forecast & Analysis", "‚öôÔ∏è Model Configuration"])

    with tab1:
        st.subheader("Generate & Analyze Sales Forecasts")

        if uploaded_file is not None:
            # Load and process uploaded file
            try:
                test_data = pd.read_csv(uploaded_file, low_memory=False)

                # --- Step 1: Data Preview ---
                st.markdown("#### Input Data Preview")
                preview_col, btn_col = st.columns([3, 1])
                with preview_col:
                    st.dataframe(test_data.head(), use_container_width=True)

                with btn_col:
                    if st.button("‚ñ∂Ô∏è 1. Generate Predictions", type="primary", use_container_width=True):

                        original_ids = test_data['Id'].copy()
                        original_dates = test_data['Date'].copy()

                        # Preprocess data
                        X_pred = preprocess_for_prediction(test_data.copy(), features)

                        if X_pred.shape[1] != len(features):
                            st.error(f"Feature column mismatch. Expected {len(features)} features, but prepared data has {X_pred.shape[1]}. Check data quality.")
                        else:
                            with st.spinner('Calculating forecast...'):
                                predictions = predict_sales(model, X_pred)

                                # Create final output DataFrame
                                results_df = pd.DataFrame({
                                    'Id': original_ids,
                                    'Date': original_dates,
                                    'Predicted Sales (EUR)': np.round(predictions, 2)
                                })

                                st.session_state['results'] = results_df

                            st.success("Forecast Complete! Results and Analysis displayed below.")

                # --- Step 2: Results & Visualization ---
                if 'results' in st.session_state:
                    results_df = st.session_state['results']

                    st.markdown("---")
                    st.markdown("#### 2. Forecast Summary & Key Metrics")

                    # Summary Metrics
                    total_sales = results_df['Predicted Sales (EUR)'].sum()
                    avg_sales = results_df['Predicted Sales (EUR)'].mean()
                    total_records = len(results_df)

                    metric_col1, metric_col2, metric_col3 = st.columns(3)
                    metric_col1.metric("Total Predicted Sales", f"‚Ç¨{total_sales:,.0f}", help="Sum of all predicted sales in the batch.")
                    metric_col2.metric("Average Daily Sales", f"‚Ç¨{avg_sales:,.0f}", help="Mean predicted daily sales per row.")
                    metric_col3.metric("Total Forecast Period (Days)", f"{total_records:,}")

                    st.markdown("---")
                    st.markdown("#### 3. Visual Analysis of Forecast")

                    # Charts
                    chart_col1, chart_col2 = st.columns([1, 1])
                    with chart_col1:
                        st.markdown("**Predicted Sales Trend Over Time**")
                        plot_sales_over_time(results_df)

                    with chart_col2:
                        st.markdown("**Predicted Sales Distribution**")
                        plot_sales_distribution(results_df)

                    st.markdown("---")
                    st.markdown("#### 4. Raw Results & Export")
                    st.dataframe(results_df.head(10), use_container_width=True)

                    # Download button
                    csv = results_df.to_csv(index=False).encode('utf-8')
                    st.download_button(
                        label="‚¨áÔ∏è Download Full Predictions CSV",
                        data=csv,
                        file_name='sales_predictions.csv',
                        mime='text/csv',
                        use_container_width=True
                    )
                else:
                    st.info("Click 'Generate Predictions' after uploading your file to see the forecast analysis.")

            except Exception as e:
                st.error(f"An error occurred during file processing or prediction: {e}")

        else:
            st.warning("üëà Please upload a CSV file (e.g., `test.csv`) in the sidebar to start batch prediction.")


    with tab2:
        st.subheader("Model Configuration & Technical Details")
        st.markdown("This tab provides transparency into the LightGBM model's architecture, helping you understand how the forecast is generated.")

        col_params, col_features = st.columns([1, 1])

        with col_params:
            st.markdown("#### Hyperparameters & Strategy")
            st.json({
                "Model Used": "LightGBM (Gradient Boosting)",
                "Objective": "Regression with L1 Loss (robust to outliers)",
                "Target Transformation": "Log-transform (np.log1p) of Sales",
                "Evaluation Metric": "Root Mean Squared Error (RMSE)",
                "Cross-Validation Strategy": "Time Series Split (5 folds)",
                "Key Hyperparameters": {
                    "Learning Rate": 0.03,
                    "Num Leaves": 40,
                    "Feature Fraction": 0.7,
                    "Bagging Fraction": 0.6
                }
            })

        with col_features:
            st.markdown("#### Feature Importance")
            st.markdown("Visual representation of which input features contribute most significantly to the final sales prediction.")
            try:
                if os.path.exists('feature_importance.png'):
                    st.image(Image.open('feature_importance.png'), caption='Feature Importance (Gain)', use_column_width=True)
                else:
                    st.warning("Feature importance chart not found. Run `model_trainer.py` to generate the image.")
            except Exception as e:
                st.error(f"Could not load feature importance image: {e}")

        st.markdown("---")
        st.subheader("Full List of Features Used")
        if features:
            feature_cols = st.columns(4) # More columns for compactness
            chunk_size = len(features) // 4 + 1
            for i, col in enumerate(feature_cols):
                start = i * chunk_size
                end = min((i + 1) * chunk_size, len(features))
                col.code("\n".join(features[start:end]), language='text')

if __name__ == "__main__":
    main()

